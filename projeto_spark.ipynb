{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b48e863-8e93-45c0-938d-c9a4566b69b8",
   "metadata": {},
   "source": [
    "# Projeto Spark\n",
    "\n",
    "Alunos:\n",
    "\n",
    "- Davi Reis\n",
    "- Guilherme Rameh\n",
    "- Nicolas Queiroga\n",
    "\n",
    "Entrega: 6 de dezembro de 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4813f033-927b-46ca-8977-30e8b0de48c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Introdução\n",
    "\n",
    "Neste projeto vamos construir um classificador Naive-Bayes para determinar o sentimento de um comentário."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7c97a3",
   "metadata": {},
   "source": [
    "## Instalando o ambiente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9b3746",
   "metadata": {},
   "source": [
    "O jeito mais simples de começar a trabalhar com Spark é instalar um container com tudo pronto! No site https://hub.docker.com/r/jupyter/pyspark-notebook vemos uma imagem Docker que já vem com `pyspark` e `jupyter lab`. Instale a imagem com o comando:\n",
    "\n",
    "```bash\n",
    "docker pull jupyter/pyspark-notebook\n",
    "```\n",
    "\n",
    "Vamos iniciar o ambiente de trabalho com o comando `docker run`. Para isso precisamos tomar alguns cuidados:\n",
    "\n",
    "1) Temos que mapear nosso diretorio local de trabalho para um diretório interno do container, de modo que alterações feitas dentro do container (nesta pasta escolhida) sejam gravadas no nosso diretorio local. No container temos um usuário padrão com *username* `jovyan`. No *homedir* desse usuario temos uma pasta vazia `work`, que vai servir como local de mapeamento do nosso diretorio local de trabalho. Podemos então fazer esse mapeamendo com a opção `-v` do comando `docker run` da seguinte forma:\n",
    "\n",
    "```bash\n",
    "-v <diretorio>:/home/jovyan/work\n",
    "```\n",
    "\n",
    "onde `<diretorio>` representa seu diretorio local de trabalho.\n",
    "\n",
    "2) Para acessar o `jupyter notebook` e o *dashboard* do Spark a partir do nosso *browser* favorito temos que abrir algumas portas do container com a opção `-p`. As portas são `8888` (para o próprio `jupyter notebook`) e `4040` (para o *dashboard* do Spark). Ou seja, adicionaremos às opções do `docker run`o seguinte:\n",
    "\n",
    "```bash\n",
    "-p 8888:8888 -p 4040:4040\n",
    "```\n",
    "\n",
    "Desta forma, ao acessar `localhost:8888` na nossa máquina, estaremos acessando o servidor Jupyter na porta 8888 interna do container.\n",
    "\n",
    "3) Vamos iniciar o container no modo interativo, e vamos especificar que o container deve ser encerrado ao fechar o servidor Jupyter. Faremos isso com as opções `-it` e `-rm`\n",
    "\n",
    "Portanto, o comando completo que eu uso na minha máquina Linux para iniciar o container é:\n",
    "\n",
    "```bash\n",
    "docker run \\\n",
    "    -it \\\n",
    "    --rm \\\n",
    "    -p 8888:8888 \\\n",
    "    -p 4040:4040 \\\n",
    "    -v `pwd`:/home/jovyan/work \\\n",
    "    jupyter/pyspark-notebook\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "Para facilitar a vida eu coloco esse comando em um arquivo `inicia.sh`. Engenheiros, façam do jeito que preferirem!\n",
    "\n",
    "Agora abra esse notebook lá no container!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3090720d-0dec-48ff-a8da-921b62764c43",
   "metadata": {},
   "source": [
    "## Iniciando o Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603fa191-ca53-4035-9147-86f3cf27831a",
   "metadata": {},
   "source": [
    "Vamos iniciar o ambiente Spark. Para isso vamos:\n",
    "\n",
    "1) Criar um objeto de configuração do ambiente Spark. Nossa configuração será simples: vamos especificar que o nome da nossa aplicação Spark é \"Minha aplicação\", e que o *master node* é a máquina local, usando todos os *cores* disponíveis. Aplicações reais de Spark são configuradas de modo ligeiramente diferente: ao especificar o *master node* passamos uma URL real, com o endereço do nó gerente do *cluster* Spark.\n",
    "\n",
    "2) Vamos criar um objeto do tipo `SparkContext` com essa configuração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d1b7f8-ddc9-43b0-adbd-2b6e5aad182c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "conf = pyspark.SparkConf()\n",
    "conf.setAppName('Projeto Spark')\n",
    "conf.setMaster('local[*]')\n",
    "\n",
    "sc = pyspark.SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfcd1c3-3c9b-47c6-bf36-06c60b796991",
   "metadata": {},
   "source": [
    "O `SparkContext` é a nossa porta de entrada para o cluster Spark, ele será a raiz de todas as nossas operações com o Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5214f8ff-9df1-4817-9e08-c1755470f3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60acb677-070b-4191-bbad-ee16000ff380",
   "metadata": {},
   "source": [
    "O link acima provavelmente não funcionará porque ele se refere à porta 4040 interna do container (portanto a URL está com endereço interno). Porém fizemos o mapeamento da porta 4040 interna para a porta 4040 externa, logo você pode acessar o *dashboard* do Spark no endereço http://localhost:4040\n",
    "\n",
    "<center><img src=\"./spark_dashboard.png\" width=800/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44bd07e-7f64-4c0d-b522-faf5313b53cc",
   "metadata": {},
   "source": [
    "## Lendo os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c2f3af",
   "metadata": {},
   "source": [
    "Vamos começar lendo o arquivo de reviews e gravando o resultado em formato pickle, mais amigável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7fda56-bf06-4309-a265-26e553e20b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_line(line):\n",
    "    parts = line[1:-1].split('\",\"')\n",
    "    sentiment = int(parts[0])\n",
    "    title = parts[1].replace('\"\"', '\"')\n",
    "    body = parts[2].replace('\"\"', '\"')\n",
    "    return (sentiment, title, body)\n",
    "\n",
    "rdd = sc.textFile('train.csv').map(parse_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900ea746-984c-405b-a449-d6cf8885525e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83f38e5-3d7b-4261-8ab3-caadb39d6076",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339c7933-ad3f-4a17-bf89-8e1360ddc4ab",
   "metadata": {},
   "source": [
    "Agora vamos gravar no formato pickle, para facilitar os trabalhos futuros. Após gravar o arquivo, não mais rode as células desta primeira etapa!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39938d62-bc17-4243-a9e8-3fed9c8d2bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.saveAsPickleFile('reviews.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4f5b5b-f0ac-4385-866b-8d8d8ecbdf9f",
   "metadata": {},
   "source": [
    "## Um classificador Naive-Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9ef2e6-ac48-46ad-b538-920c17aff6dc",
   "metadata": {},
   "source": [
    "Vamos ler o arquivo pickle gravado anteriormente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9107ce80-0447-41d7-8f83-d96f0680d8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.pickleFile('reviews.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae84b476-b262-496f-93b0-19386fa9f29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607f7afa-43e7-4b82-bffc-7c1cca0536ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9751aa-df6d-4e3e-a8c5-039133cefe28",
   "metadata": {},
   "source": [
    "Agora, complete as tarefas em sequencia para construir o classificador Naive-Bayes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bac409-7181-49c4-b555-73d3e9ff71f2",
   "metadata": {},
   "source": [
    "### Fase 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165de817",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef78654e-d064-41b4-9be8-306a57c425f4",
   "metadata": {},
   "source": [
    "#### Tarefa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03d82f8-520e-49de-8397-5277d5bd072e",
   "metadata": {},
   "source": [
    "Construa uma função que recebe um RDD no formato do RDD original e retorna um RDD no qual cada item é um par (palavra, contagem)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0872998c-3fbd-4f16-a970-12e9f22e7062",
   "metadata": {},
   "source": [
    "Na função abaixo, importante notar que precisamos percorrer tanto o título como o corpo de cada avaliação do RDD original. O \"reduceByKey\" agrupa todas as palavras com a contagem que o map faz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb48e97-e57d-4b6a-9b27-b52cd9c3d195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(rdd):\n",
    "    return rdd.flatMap(lambda x: x[1].split() + x[2].split()).map(lambda x: (x, 1)).reduceByKey(lambda x, y: x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d888c4-bef5-4d1c-a901-e8dc5029f1b0",
   "metadata": {},
   "source": [
    "#### Tarefa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ec5621-6c06-4dce-b351-e887d6aa8be4",
   "metadata": {},
   "source": [
    "Construa uma função que recebe o RDD (palavra, contagem) construido anteriormente e retorna um RDD no qual cada item é um par (palavra, $\\log_{10}\\left(c \\, / \\, T\\right)$), onde $c$ é a contagem daquela palavra e $T$ é a soma das contagens de palavra."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9163c033-430e-48db-976f-dd8b1e5b4d9b",
   "metadata": {},
   "source": [
    "Essa função apenas usa o reduce para contar o total de palavras, e depois faz a conta com o log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca379b49-a447-4ecf-9946-6c408e2adc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_log_count(rdd):\n",
    "    total_count = rdd.map(lambda x: x[1]).reduce(lambda x, y: x + y)\n",
    "    return rdd.map(lambda x: (x[0], np.log10(x[1] / total_count)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09116064-380c-43ed-91a3-736c80b47fb9",
   "metadata": {},
   "source": [
    "#### Tarefa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47df9afe-f429-4951-954d-8ac0361efee6",
   "metadata": {},
   "source": [
    "Separe o RDD original em dois RDDs: o dos reviews positivos e o dos negativos. Em seguida, use as funções anteriores para construir RDDs que contem os pares (palavra, $\\log_{10}\\left(c \\, / \\, T\\right)$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f92b24-11d6-4e8c-bc6a-3b317071c582",
   "metadata": {},
   "source": [
    "Para separar os RDDs, basta ver a classificação do RDD original, se for 1 é positivo, se for 2 é negativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987554e0-0a16-4827-9cc3-7c21063b1f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_sentiment(rdd):\n",
    "    positive = rdd.filter(lambda x: x[0] == 1)\n",
    "    negative = rdd.filter(lambda x: x[0] == 2)\n",
    "    return positive, negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9fb0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_positive, rdd_negative = split_by_sentiment(rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84988f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_positive_log_count = word_log_count(word_count(rdd_positive))\n",
    "rdd_negative_log_count = word_log_count(word_count(rdd_negative))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfe5957-73d2-45ad-9ad2-6e029668bacf",
   "metadata": {},
   "source": [
    "### Tarefa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904cb0c8-2236-47aa-8ab0-3ad925bb24ed",
   "metadata": {},
   "source": [
    "Use o `.fullOuterJoin()` dos RDDs para construir um RDD unificado, no qual cada item é da forma (palavra, log_prob_positivo, log_prob_negativo). \"Baixe\" esse resultado final usando `.collect()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b599156-e71d-46b4-9499-8d2dfe072512",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_unified = rdd_positive_log_count.fullOuterJoin(rdd_negative_log_count).map(lambda x: (x[0], x[1][0], x[1][1]))\n",
    "\n",
    "rdd_unified.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571825d8",
   "metadata": {},
   "source": [
    "- Testando para a palavra 'Slow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3c8d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_positive_log_count.filter(lambda x: x[0] == 'Slow').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746eb6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_negative_log_count.filter(lambda x: x[0] == 'Slow').collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e90473-6725-4f30-9130-f5a0f370d968",
   "metadata": {},
   "source": [
    "#### Tarefa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423d2117-397c-4a66-b63b-ca00036c1e2d",
   "metadata": {},
   "source": [
    "Para uma dada string, determine se ela é um review positivo ou negativo usando os RDDs acima. Lembre-se de como funciona o classificador Naive-Bayes: http://stanford.edu/~jurafsky/slp3/slides/7_NB.pdf, consulte tambem suas notas de aula de Ciência dos Dados!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3240fbd2",
   "metadata": {},
   "source": [
    "Na célula abaixo fazemos uma classe que contem todas as funções que usamos anteriormente para calcular o log das palavras, e uma função chamada 'classify', que acumula o valor dos logs positivo e negativo de cada palavra dado uma frase passada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f68949-61c8-46b4-a39e-bcfb3872c4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self, rdd):\n",
    "        self.rdd = rdd\n",
    "        self.positive, self.negative = self.split_by_sentiment(rdd)\n",
    "        self.positive_count = self.positive.count()\n",
    "        self.negative_count = self.negative.count()\n",
    "        self.total_count = self.positive_count + self.negative_count\n",
    "        self.positive_log_count = self.word_log_count(self.word_count(self.positive))\n",
    "        self.negative_log_count = self.word_log_count(self.word_count(self.negative))\n",
    "        self.unified = self.positive_log_count.fullOuterJoin(self.negative_log_count).map(lambda x: (x[0], x[1][0], x[1][1]))\n",
    "\n",
    "    def split_by_sentiment(self, rdd):\n",
    "        positive = rdd.filter(lambda x: x[0] == 1)\n",
    "        negative = rdd.filter(lambda x: x[0] == 2)\n",
    "        return positive, negative\n",
    "\n",
    "    def word_log_count(self, rdd):\n",
    "        total_count = rdd.map(lambda x: x[1]).reduce(lambda x, y: x + y)\n",
    "        return rdd.map(lambda x: (x[0], np.log10(x[1] / total_count)))\n",
    "\n",
    "    def word_count(self, rdd):\n",
    "        return rdd.flatMap(lambda x: x[1].split()).map(lambda x: (x, 1)).reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "    def classify(self, text):\n",
    "        positive = 0\n",
    "        negative = 0\n",
    "        for word in text.split():\n",
    "            positive += self.unified.filter(lambda x: x[0] == word).map(lambda x: x[1]).collect()[0]\n",
    "            negative += self.unified.filter(lambda x: x[0] == word).map(lambda x: x[2]).collect()[0]\n",
    "        if positive < negative:\n",
    "            return 2, positive\n",
    "        else:\n",
    "            return 1, negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244ed897",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = NaiveBayes(rdd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fcd3ee",
   "metadata": {},
   "source": [
    "- Testando o classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b8642a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"The best game for my kids. I love\"\n",
    "classification, score = nb.classify(test)\n",
    "print('Classification: {}, Score: {}'.format(classification, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab052fff-3752-4476-88f5-bc6b654c8e02",
   "metadata": {},
   "source": [
    "### Fase 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7071fa13-c31b-434e-969f-538c0070fb34",
   "metadata": {},
   "source": [
    "Agora que temos um classificador Naive-Bayes, vamos explorá-lo um pouco:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ed5be5-9e8d-4a7f-98bc-592cc7ecee74",
   "metadata": {},
   "source": [
    "### Tarefa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb9bd58-1023-4cb7-861e-6cdbe5384356",
   "metadata": {},
   "source": [
    "Quais são as 100 palavras que mais indicam negatividade, ou seja, onde a diferença entre a probabilidade da palavra no conjunto dos comentários negativos e positivos é máxima? E quais as 100 palavras de maior positividade? Mostre os resultados na forma de *word clouds*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c789edaa-bb6c-4194-b855-98db9c8f11d7",
   "metadata": {},
   "source": [
    "Para delecionar as palavras positivas e negativas, basta pegar o RDD unificado, filtrar qual o sentimento que queremos (com x[][] != None) e usar o takeOrdered para selecionar os 100 maiores valores (por isso o - na frente, já que o log é negativo, é necessário pegar o módulo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c147d964-8720-43fa-a8e3-0610394a752f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_unified_fase_2 = rdd_positive_log_count.fullOuterJoin(rdd_negative_log_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd23e04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "positivity_words = rdd_unified_fase_2.filter(lambda x: x[1][0] != None).filter(lambda x: x[1][1] != None).map(lambda x:(x[0], (x[1][1]) - (x[1][0]))).takeOrdered(100, lambda x: -x[1])\n",
    "positivity_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54adbe40",
   "metadata": {},
   "outputs": [],
   "source": [
    "negativity_words = rdd_unified_fase_2.filter(lambda x: x[1][0] != None).filter(lambda x: x[1][1] != None).map(lambda x:(x[0], (x[1][0]) - (x[1][1]))).takeOrdered(100, lambda x: -x[1])\n",
    "negativity_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7207ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69243836",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_wordcloud(words):\n",
    "    wordcloud = WordCloud().generate_from_frequencies(dict(words))\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3f64f9",
   "metadata": {},
   "source": [
    "- Palavras Positivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38bbd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(positivity_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc4bf7e",
   "metadata": {},
   "source": [
    "- Palavras Negativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07b0498",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(negativity_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8854a0bf-1941-47eb-a1f5-6b3f4d34f857",
   "metadata": {},
   "source": [
    "### Tarefa desafio!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a98d11-16d6-4d97-b1ab-14db145e826e",
   "metadata": {},
   "source": [
    "Qual o desempenho do classificador (acurácia)? Para medir sua acurácia:\n",
    "\n",
    "- Separe os reviews em dois conjuntos: treinamente e teste\n",
    "- Repita o \"treinamento\" do classificador com o conjunto de treinamento\n",
    "- Para cada review do conjunto de teste, determine se é positiva ou negativa de acordo com o classificador\n",
    "- Determine a acurácia\n",
    "\n",
    "Esta não é uma tarefa trivial. Não basta fazer um `for` para determinar a classe de cada review de teste: isso demoraria uma eternidade. Você tem que usar variáveis \"broadcast\" do Spark para enviar uma cópia da tabela de frequencias para cada *core* do executor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be164a9c",
   "metadata": {},
   "source": [
    "Primeiro dividimos os dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb2b8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = rdd.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b385500b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ce4c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0537922",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train = NaiveBayes(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edacc0b1-fc7e-4eb6-87ad-35236000c8b3",
   "metadata": {},
   "source": [
    "Após treinarmos o NB, precisamos de uma função que recebe o um texto e o broadcast, e retorna a previsão. Dividimos o texto em palavras, e pra cada palavra, acumulamos o valor treinado e verificamos qual valor em módulo é maior, o positivo ou negativo, e classificamos a palavra assim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4203a68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_new(text, training_set):\n",
    "    training = training_set.value\n",
    "    \n",
    "    positive = 0\n",
    "    negative = 0\n",
    "    for word in text.split():\n",
    "        if word in training and training[word][0] != None and training[word][1] != None:\n",
    "            positive += training[word][0]\n",
    "            negative += training[word][1]\n",
    "    if positive <negative:\n",
    "        return 2, positive\n",
    "    else:\n",
    "        return 1, negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba00c13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "all_words = nb_train.unified.collect()\n",
    "\n",
    "all_words_dict = {}\n",
    "for word in all_words:\n",
    "    all_words_dict[word[0]] = word[1:]\n",
    "\n",
    "training_set = sc.broadcast(all_words_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81487439",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_new_final = partial(classify_new, training_set=training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd7f31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classify_new_final('The best game for my kids. I love'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12103c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classified = test.map(lambda x: (x[0], x[1], classify_new_final(x[1])))\n",
    "test_classified.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791078a6",
   "metadata": {},
   "source": [
    "- Analisando a acurácia do classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6f0d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = test_classified.filter(lambda x: x[0] == x[2][0]).count()\n",
    "total = test_classified.count()\n",
    "print(total)\n",
    "accuracy = correct / total\n",
    "print('Accuracy: {:.3f}%'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12a2c0d-7bfc-40bf-b717-1414c1df05ec",
   "metadata": {},
   "source": [
    "### Tarefa desafio!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af21c4e-5a5b-4127-80a0-d79e95f03b8f",
   "metadata": {},
   "source": [
    "Implemente Laplace smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1456979c-a127-4bff-bbde-7c19cc95e069",
   "metadata": {},
   "source": [
    "Função que implementa o Laplace Smoothing na associação dos logs para cada palavra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f61c989-ec58-4ebe-be19-595ad9e4887c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplace_smoothing(rdd, T, v=171476, alpha=1):\n",
    "    op = rdd.map(lambda x: (x[0], np.log10((x[1] + alpha) / (T[1] + alpha * v))))\n",
    "    return op"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91794f90-7f95-49be-a62f-a618189221f9",
   "metadata": {},
   "source": [
    "Aplicamos o Laplace smoothing para a divisão positiva e negativa, e agrupamos ambos com um fullOuterJoin, para transformarmos esse RDD em um dicionário. A partir dele fazemos o broadcast que será usado novamente na classificação.\n",
    "\n",
    "A partir daqui, repitimos todo o processo aterior, de treinamento e teste a partir da classe NB, checamos sua acurácia e verificamos as 100 palavras mais negativas e positivas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58a0072-f6a4-437b-96de-48c2ace50ff7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "count = word_count(rdd)\n",
    "T = count.reduce(lambda x, y: (\"all\", x[1] + y[1]))\n",
    "smoothing = laplace_smoothing(rdd=count, T=T).take(10)\n",
    "smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0f99f0-f2db-4ec0-a6b0-cd92baa0d140",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "count = word_count(rdd_negative)\n",
    "T = count.reduce(lambda x, y: (\"all\", x[1] + y[1]))\n",
    "smoothing_negative = laplace_smoothing(rdd=count, T=T)\n",
    "smoothing_negative.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dd67d1-b645-4f67-8c52-3ccf587234e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "count = word_count(rdd_positive)\n",
    "T = count.reduce(lambda x, y: (\"all\", x[1] + y[1]))\n",
    "smoothing_positive = laplace_smoothing(rdd=count, T=T)\n",
    "smoothing_positive.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a05303a-8cc3-4723-9813-7584fe1e8128",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_smoothings = smoothing_negative.fullOuterJoin(smoothing_positive).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22cc760-9c1f-4640-9303-3664cb65c09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothing_dict = {a: [b] for a, b in all_smoothings}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be2fa5a-9661-49f8-b140-ce5cb01e7536",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_laplace = sc.broadcast(smoothing_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f515da4-e94e-4415-a09b-c215345be7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_new(text, training, v=171476):\n",
    "    positive = 0\n",
    "    negative = 0\n",
    "    for word in text.split():\n",
    "        if word in training:\n",
    "            if training[word][0][0] != None:\n",
    "                positive += training[word][0][0]\n",
    "            else:\n",
    "                positivo += np.log10(1.0/v)\n",
    "            if training[word][0][1] != None:\n",
    "                negative += training[word][0][1]\n",
    "            else:\n",
    "                negative += np.log10(1.0/v)\n",
    "        \n",
    "    if positive < negative:\n",
    "        return 2, positive\n",
    "    else:\n",
    "        return 1, negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2deef0f-2d2f-4f11-87ad-d6856fa1ff53",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_new_final = partial(classify_new, training=training_set_laplace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7124ee3d-2c6a-4735-93a1-80b03103d573",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_new_final('i love it')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10558df6-a82b-45e2-9156-f7cbc13ecf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classified = test.map(lambda x: (x[0], x[1], classify_new_final(x[1])))\n",
    "test_classified.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb867111-08dd-4994-861a-509870c81788",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = test_classified.filter(lambda x: x[0] == x[2][0])\n",
    "total = test_classified.count()\n",
    "print(total)\n",
    "accuracy = correct / total\n",
    "print('Accuracy: {:.3f}%'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf082f3-7918-477b-b9ed-3e76de4455f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_smoothings = smoothing_negative.fullOuterJoin(smoothing_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147b4aa1-98ae-450a-8509-2f3bce0922df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "positive_words = all_smoothings \\\n",
    "                    .filter(lambda x: x[1][0] != None and x[1][1] != None)\\\n",
    "                    .takeOrdered(100, lambda x: -x[1][0])\n",
    "positive_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9df39f9-972f-4de4-b8bf-a08aecb19474",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "negative_words = all_smoothings \\\n",
    "                    .filter(lambda x: x[1][0] != None and x[1][1] != None)\\\n",
    "                    .takeOrdered(100, lambda x: -x[1][1])\n",
    "negative_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c381253-90f5-48c7-9ba6-aad54ff3289d",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_smoothing_text = \" \".join(word[0] for word in negative_words)\n",
    "plot_wordcloud(negative_smoothing_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10b5bc8-f80d-469d-b876-7884ca8dbfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_smoothing_text = \" \".join(word[0] for word in positive_words)\n",
    "plot_wordcloud(positive_smoothing_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08805b7b-f8b5-4b85-ab53-3c0813f79c44",
   "metadata": {},
   "source": [
    "## Rubrica de avaliação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74059567-1f3d-414a-bbc8-f5a7ea144b76",
   "metadata": {},
   "source": [
    "- I: groselha, falha crítica, ou não entregou nada\n",
    "- D: Fez uma tentativa honesta de fazer todos os itens da fase 1, mas tem erros\n",
    "- C: Fase 1 completa OK\n",
    "- B: Fase 2, faltando apenas um desafio OK\n",
    "- A: Fase 2 completa OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef48ef89-ae34-4115-938b-7e8d4f87694f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "550d6d0f65dc70a312dc8994351c73ab5d44b7eba20972623dc756e9c29672d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
